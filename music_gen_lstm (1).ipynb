{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: schubert/schubert_D850_1.mid\n",
      "Loading Music File: schubert/schubert_D850_2.mid\n",
      "Loading Music File: schubert/schubert_D850_3.mid\n",
      "Loading Music File: schubert/schubert_D850_4.mid\n",
      "Loading Music File: schubert/schubert_D935_1.mid\n",
      "Loading Music File: schubert/schubert_D935_2.mid\n",
      "Loading Music File: schubert/schubert_D935_3.mid\n",
      "Loading Music File: schubert/schubert_D935_4.mid\n",
      "Loading Music File: schubert/schub_d760_1.mid\n",
      "Loading Music File: schubert/schub_d760_2.mid\n",
      "Loading Music File: schubert/schub_d760_3.mid\n",
      "Loading Music File: schubert/schub_d760_4.mid\n",
      "Loading Music File: schubert/schub_d960_1.mid\n",
      "Loading Music File: schubert/schub_d960_2.mid\n",
      "Loading Music File: schubert/schub_d960_3.mid\n",
      "Loading Music File: schubert/schub_d960_4.mid\n",
      "Loading Music File: schubert/schuim-1.mid\n",
      "Loading Music File: schubert/schuim-2.mid\n",
      "Loading Music File: schubert/schuim-3.mid\n",
      "Loading Music File: schubert/schuim-4.mid\n",
      "Loading Music File: schubert/schumm-1.mid\n",
      "Loading Music File: schubert/schumm-2.mid\n",
      "Loading Music File: schubert/schumm-3.mid\n",
      "Loading Music File: schubert/schumm-4.mid\n",
      "Loading Music File: schubert/schumm-5.mid\n",
      "Loading Music File: schubert/schumm-6.mid\n",
      "Loading Music File: schubert/schu_143_1.mid\n",
      "Loading Music File: schubert/schu_143_2.mid\n",
      "Loading Music File: schubert/schu_143_3.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crack\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='schubert/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([187.,  41.,  26.,  11.,   6.,   9.,  12.,   6.,   3.,   3.]),\n",
       " array([1.0000e+00, 1.4790e+02, 2.9480e+02, 4.4170e+02, 5.8860e+02,\n",
       "        7.3550e+02, 8.8240e+02, 1.0293e+03, 1.1762e+03, 1.3231e+03,\n",
       "        1.4700e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crack\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128,return_sequences=True))\n",
    "  model.add(LSTM(128))\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dense(n_vocab))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 32, 100)           16700     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 167)               42919     \n",
      "=================================================================\n",
      "Total params: 267,939\n",
      "Trainable params: 267,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crack\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51530 samples, validate on 12883 samples\n",
      "Epoch 1/50\n",
      "51530/51530 [==============================] - 18s 353us/step - loss: 4.3053 - val_loss: 4.0123\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.01231, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "51530/51530 [==============================] - 18s 347us/step - loss: 3.7962 - val_loss: 3.8574\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.01231 to 3.85736, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 3.6263 - val_loss: 3.7036\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.85736 to 3.70358, saving model to best_model.h5\n",
      "Epoch 4/50\n",
      "51530/51530 [==============================] - 17s 337us/step - loss: 3.4883 - val_loss: 3.5703\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.70358 to 3.57026, saving model to best_model.h5\n",
      "Epoch 5/50\n",
      "51530/51530 [==============================] - 18s 344us/step - loss: 3.3814 - val_loss: 3.4869\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.57026 to 3.48693, saving model to best_model.h5\n",
      "Epoch 6/50\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 3.2912 - val_loss: 3.4058\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.48693 to 3.40578, saving model to best_model.h5\n",
      "Epoch 7/50\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 3.2152 - val_loss: 3.3742\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.40578 to 3.37423, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 3.1494 - val_loss: 3.2999\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.37423 to 3.29993, saving model to best_model.h5\n",
      "Epoch 9/50\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 3.0873 - val_loss: 3.2543\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.29993 to 3.25427, saving model to best_model.h5\n",
      "Epoch 10/50\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 3.0404 - val_loss: 3.2280\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.25427 to 3.22800, saving model to best_model.h5\n",
      "Epoch 11/50\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 2.9890 - val_loss: 3.2256\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.22800 to 3.22559, saving model to best_model.h5\n",
      "Epoch 12/50\n",
      "51530/51530 [==============================] - 17s 339us/step - loss: 2.9437 - val_loss: 3.1851\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.22559 to 3.18508, saving model to best_model.h5\n",
      "Epoch 13/50\n",
      "51530/51530 [==============================] - 18s 341us/step - loss: 2.9069 - val_loss: 3.1240\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.18508 to 3.12401, saving model to best_model.h5\n",
      "Epoch 14/50\n",
      "51530/51530 [==============================] - 18s 351us/step - loss: 2.8649 - val_loss: 3.1198\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.12401 to 3.11976, saving model to best_model.h5\n",
      "Epoch 15/50\n",
      "51530/51530 [==============================] - 18s 355us/step - loss: 2.8314 - val_loss: 3.0838\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.11976 to 3.08380, saving model to best_model.h5\n",
      "Epoch 16/50\n",
      "51530/51530 [==============================] - 18s 357us/step - loss: 2.8052 - val_loss: 3.0638\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.08380 to 3.06379, saving model to best_model.h5\n",
      "Epoch 17/50\n",
      "51530/51530 [==============================] - 18s 357us/step - loss: 2.7750 - val_loss: 3.0496\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.06379 to 3.04955, saving model to best_model.h5\n",
      "Epoch 18/50\n",
      "51530/51530 [==============================] - 19s 367us/step - loss: 2.7465 - val_loss: 3.0478\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.04955 to 3.04778, saving model to best_model.h5\n",
      "Epoch 19/50\n",
      "51530/51530 [==============================] - 19s 364us/step - loss: 2.7175 - val_loss: 2.9983\n",
      "\n",
      "Epoch 00019: val_loss improved from 3.04778 to 2.99825, saving model to best_model.h5\n",
      "Epoch 20/50\n",
      "51530/51530 [==============================] - 18s 356us/step - loss: 2.6980 - val_loss: 2.9894\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.99825 to 2.98937, saving model to best_model.h5\n",
      "Epoch 21/50\n",
      "51530/51530 [==============================] - 19s 366us/step - loss: 2.6713 - val_loss: 2.9674\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.98937 to 2.96736, saving model to best_model.h5\n",
      "Epoch 22/50\n",
      "51530/51530 [==============================] - 19s 359us/step - loss: 2.6547 - val_loss: 2.9954\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.96736\n",
      "Epoch 23/50\n",
      "51530/51530 [==============================] - 19s 364us/step - loss: 2.6300 - val_loss: 2.9521\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.96736 to 2.95213, saving model to best_model.h5\n",
      "Epoch 24/50\n",
      "51530/51530 [==============================] - 19s 362us/step - loss: 2.6116 - val_loss: 2.9334\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.95213 to 2.93345, saving model to best_model.h5\n",
      "Epoch 25/50\n",
      "51530/51530 [==============================] - 19s 369us/step - loss: 2.5931 - val_loss: 2.9290\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.93345 to 2.92904, saving model to best_model.h5\n",
      "Epoch 26/50\n",
      "51530/51530 [==============================] - 19s 361us/step - loss: 2.5772 - val_loss: 2.9254\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.92904 to 2.92540, saving model to best_model.h5\n",
      "Epoch 27/50\n",
      "51530/51530 [==============================] - 18s 355us/step - loss: 2.5648 - val_loss: 2.9249\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.92540 to 2.92485, saving model to best_model.h5\n",
      "Epoch 28/50\n",
      "51530/51530 [==============================] - 18s 355us/step - loss: 2.5454 - val_loss: 2.8943\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.92485 to 2.89425, saving model to best_model.h5\n",
      "Epoch 29/50\n",
      "51530/51530 [==============================] - 19s 372us/step - loss: 2.5328 - val_loss: 2.8875\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.89425 to 2.88751, saving model to best_model.h5\n",
      "Epoch 30/50\n",
      "51530/51530 [==============================] - 18s 357us/step - loss: 2.5190 - val_loss: 2.8802\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.88751 to 2.88025, saving model to best_model.h5\n",
      "Epoch 31/50\n",
      "51530/51530 [==============================] - 19s 359us/step - loss: 2.5009 - val_loss: 2.8821\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.88025\n",
      "Epoch 32/50\n",
      "51530/51530 [==============================] - 18s 357us/step - loss: 2.4949 - val_loss: 2.8587\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.88025 to 2.85868, saving model to best_model.h5\n",
      "Epoch 33/50\n",
      "51530/51530 [==============================] - 19s 360us/step - loss: 2.4810 - val_loss: 2.8669\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.85868\n",
      "Epoch 34/50\n",
      "51530/51530 [==============================] - 18s 358us/step - loss: 2.4685 - val_loss: 2.8453\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.85868 to 2.84530, saving model to best_model.h5\n",
      "Epoch 35/50\n",
      "51530/51530 [==============================] - 19s 361us/step - loss: 2.4559 - val_loss: 2.8411\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.84530 to 2.84108, saving model to best_model.h5\n",
      "Epoch 36/50\n",
      "51530/51530 [==============================] - 18s 358us/step - loss: 2.4474 - val_loss: 2.8484: 0s - loss: 2.\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.84108\n",
      "Epoch 37/50\n",
      "51530/51530 [==============================] - 19s 363us/step - loss: 2.4351 - val_loss: 2.8275\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.84108 to 2.82750, saving model to best_model.h5\n",
      "Epoch 38/50\n",
      "51530/51530 [==============================] - 19s 362us/step - loss: 2.4293 - val_loss: 2.8354\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.82750\n",
      "Epoch 39/50\n",
      "51530/51530 [==============================] - 18s 359us/step - loss: 2.4193 - val_loss: 2.8219\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.82750 to 2.82190, saving model to best_model.h5\n",
      "Epoch 40/50\n",
      "51530/51530 [==============================] - 18s 358us/step - loss: 2.4057 - val_loss: 2.8213\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.82190 to 2.82128, saving model to best_model.h5\n",
      "Epoch 41/50\n",
      "51530/51530 [==============================] - 19s 364us/step - loss: 2.4056 - val_loss: 2.8061\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.82128 to 2.80611, saving model to best_model.h5\n",
      "Epoch 42/50\n",
      "51530/51530 [==============================] - 19s 371us/step - loss: 2.3989 - val_loss: 2.8051\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.80611 to 2.80515, saving model to best_model.h5\n",
      "Epoch 43/50\n",
      "51530/51530 [==============================] - 19s 360us/step - loss: 2.3922 - val_loss: 2.7980\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.80515 to 2.79804, saving model to best_model.h5\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 19s 359us/step - loss: 2.3838 - val_loss: 2.7952\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.79804 to 2.79520, saving model to best_model.h5\n",
      "Epoch 45/50\n",
      "51530/51530 [==============================] - 18s 353us/step - loss: 2.3680 - val_loss: 2.7967\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.79520\n",
      "Epoch 46/50\n",
      "51530/51530 [==============================] - 18s 354us/step - loss: 2.3602 - val_loss: 2.7995\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.79520\n",
      "Epoch 47/50\n",
      "51530/51530 [==============================] - 18s 354us/step - loss: 2.3488 - val_loss: 2.7892\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.79520 to 2.78923, saving model to best_model.h5\n",
      "Epoch 48/50\n",
      "51530/51530 [==============================] - 18s 353us/step - loss: 2.3458 - val_loss: 2.7729\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.78923 to 2.77287, saving model to best_model.h5\n",
      "Epoch 49/50\n",
      "51530/51530 [==============================] - 18s 356us/step - loss: 2.3448 - val_loss: 2.7745\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.77287\n",
      "Epoch 50/50\n",
      "51530/51530 [==============================] - 18s 355us/step - loss: 2.3346 - val_loss: 2.7692\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.77287 to 2.76918, saving model to best_model.h5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crack\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 131, 27, 28, 27, 46, 27, 28, 27, 27]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
